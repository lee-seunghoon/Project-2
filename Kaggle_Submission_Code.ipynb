{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mexican-granny",
   "metadata": {
    "papermill": {
     "duration": 0.014894,
     "end_time": "2021-04-26T17:49:16.340454",
     "exception": false,
     "start_time": "2021-04-26T17:49:16.325560",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 라이브러리 모음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "coated-accommodation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T17:49:16.373503Z",
     "iopub.status.busy": "2021-04-26T17:49:16.372053Z",
     "iopub.status.idle": "2021-04-26T17:50:22.517525Z",
     "shell.execute_reply": "2021-04-26T17:50:22.516407Z"
    },
    "papermill": {
     "duration": 66.163156,
     "end_time": "2021-04-26T17:50:22.517697",
     "exception": false,
     "start_time": "2021-04-26T17:49:16.354541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/external-model/Keras_Applications-1.0.8-py3-none-any.whl\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from Keras-Applications==1.0.8) (2.10.0)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from Keras-Applications==1.0.8) (1.19.5)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->Keras-Applications==1.0.8) (1.15.0)\r\n",
      "Installing collected packages: Keras-Applications\r\n",
      "Successfully installed Keras-Applications-1.0.8\r\n",
      "Processing /kaggle/input/external-model/efficientnet-1.1.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.1.0) (0.18.1)\r\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.1.0) (1.0.8)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (1.19.5)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (2.10.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet==1.1.0) (1.15.0)\r\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2.9.0)\r\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2.5)\r\n",
      "Requirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (1.5.4)\r\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (2021.3.17)\r\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (3.4.0)\r\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (1.1.1)\r\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.1.0) (7.2.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (0.10.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (2.4.7)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.1.0) (2.8.1)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.1.0) (4.4.2)\r\n",
      "Installing collected packages: efficientnet\r\n",
      "Successfully installed efficientnet-1.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ../input/external-model/Keras_Applications-1.0.8-py3-none-any.whl\n",
    "!pip install ../input/external-model/efficientnet-1.1.0-py3-none-any.whl\n",
    "\n",
    "# 파일 처리\n",
    "import os\n",
    "\n",
    "# Data 처리\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "##############################################################\n",
    "\n",
    "# RAPIDS 라이브러리\n",
    "import cudf, cuml, cupy \n",
    "from cuml.feature_extraction.text import TfidfVectorizer\n",
    "from cuml.neighbors import NearestNeighbors\n",
    "##############################################################\n",
    "\n",
    "# ML, DNN, CNN 관련 라이브러리\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Input, GlobalAveragePooling2D, Softmax\n",
    "\n",
    "#!pip install efficientnet\n",
    "import efficientnet.tfkeras as efn\n",
    "import math\n",
    "##############################################################\n",
    "\n",
    "# 이미지 및 그래프 출력\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "##############################################################\n",
    "\n",
    "# 해쉬(phash) 값 처리\n",
    "import imagehash\n",
    "\n",
    "##############################################################\n",
    "\n",
    "# Text Data NLP 처리\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.neighbors import NearestNeighbors\n",
    "import re\n",
    "import nltk\n",
    "# nltk.download('popular')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "from shutil import copyfile\n",
    "copyfile(src = \"../input/bert-baseline/tokenization.py\", dst = \"../working/tokenization.py\")\n",
    "\n",
    "import tokenization\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "##############################################################\n",
    "\n",
    "# 메모리 관리\n",
    "import gc\n",
    "\n",
    "# 경고메시지 지우기\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# 상태바 진행상태\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Text Color\n",
    "from termcolor import colored\n",
    "\n",
    "# 실행시간 확인\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-ticket",
   "metadata": {
    "papermill": {
     "duration": 0.015901,
     "end_time": "2021-04-26T17:50:22.550244",
     "exception": false,
     "start_time": "2021-04-26T17:50:22.534343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 메모리 관리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unsigned-champagne",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T17:50:22.792787Z",
     "iopub.status.busy": "2021-04-26T17:50:22.791777Z",
     "iopub.status.idle": "2021-04-26T17:50:27.299354Z",
     "shell.execute_reply": "2021-04-26T17:50:27.298447Z"
    },
    "papermill": {
     "duration": 4.731475,
     "end_time": "2021-04-26T17:50:27.299500",
     "exception": false,
     "start_time": "2021-04-26T17:50:22.568025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will restrict TensorFlow to max 2GB GPU RAM\n",
      "then RAPIDS can use 14GB GPU RAM\n"
     ]
    }
   ],
   "source": [
    "# RESTRICT TENSORFLOW TO 2GB OF GPU RAM\n",
    "# SO THAT WE HAVE 14GB RAM FOR RAPIDS\n",
    "LIMIT = 2.0\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        #print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "print('We will restrict TensorFlow to max %iGB GPU RAM'%LIMIT)\n",
    "print('then RAPIDS can use %iGB GPU RAM'%(16-LIMIT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-december",
   "metadata": {
    "papermill": {
     "duration": 0.01635,
     "end_time": "2021-04-26T17:50:27.332901",
     "exception": false,
     "start_time": "2021-04-26T17:50:27.316551",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 변수 모음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "convertible-dynamics",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T17:50:27.374086Z",
     "iopub.status.busy": "2021-04-26T17:50:27.373183Z",
     "iopub.status.idle": "2021-04-26T17:50:27.378463Z",
     "shell.execute_reply": "2021-04-26T17:50:27.379546Z"
    },
    "papermill": {
     "duration": 0.030338,
     "end_time": "2021-04-26T17:50:27.379920",
     "exception": false,
     "start_time": "2021-04-26T17:50:27.349582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = [224, 224]\n",
    "\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "N_CLASSES = 11014\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "GET_CV = False\n",
    "\n",
    "CHECK_SUB =False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-leadership",
   "metadata": {
    "papermill": {
     "duration": 0.03269,
     "end_time": "2021-04-26T17:50:27.438847",
     "exception": false,
     "start_time": "2021-04-26T17:50:27.406157",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CV 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "genetic-kitty",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T17:50:27.507250Z",
     "iopub.status.busy": "2021-04-26T17:50:27.506670Z",
     "iopub.status.idle": "2021-04-26T17:50:27.519503Z",
     "shell.execute_reply": "2021-04-26T17:50:27.520562Z"
    },
    "papermill": {
     "duration": 0.053965,
     "end_time": "2021-04-26T17:50:27.520750",
     "exception": false,
     "start_time": "2021-04-26T17:50:27.466785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
    "# If we are comitting, replace train set for test set and dont get cv\n",
    "if len(df) > 3:\n",
    "    GET_CV = False\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-facial",
   "metadata": {
    "papermill": {
     "duration": 0.033228,
     "end_time": "2021-04-26T17:50:27.594764",
     "exception": false,
     "start_time": "2021-04-26T17:50:27.561536",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 함수 모음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "respected-amplifier",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T17:50:27.671223Z",
     "iopub.status.busy": "2021-04-26T17:50:27.668464Z",
     "iopub.status.idle": "2021-04-26T17:50:27.757992Z",
     "shell.execute_reply": "2021-04-26T17:50:27.759050Z"
    },
    "papermill": {
     "duration": 0.132531,
     "end_time": "2021-04-26T17:50:27.759257",
     "exception": false,
     "start_time": "2021-04-26T17:50:27.626726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DataSet 불러오기\n",
    "def read_dataset():\n",
    "    if GET_CV:\n",
    "        df = pd.read_csv('../input/shopee-product-matching/train.csv')\n",
    "        tmp = df.groupby(['label_group'])['posting_id'].unique().to_dict()\n",
    "        df['matches'] = df['label_group'].map(tmp)\n",
    "        df['matches'] = df['matches'].map(lambda x: ' '.join(x))\n",
    "        \n",
    "        if CHECK_SUB:\n",
    "            df = pd.concat([df, df], axis=0)\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "        df_cu =cudf.DataFrame(df)\n",
    "        image_path = '../input/shopee-product-matching/train_images/' + df['image']\n",
    "    else:\n",
    "        df = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
    "        df_cu =cudf.DataFrame(df)\n",
    "        image_path = '../input/shopee-product-matching/test_images/' + df['image']\n",
    "        \n",
    "    return df, df_cu, image_path\n",
    "\n",
    "# 예측값 결합\n",
    "def combine_preds(row):\n",
    "    x = np.concatenate([row['image_pred'], row['text_pred'], row['phash_pred']])\n",
    "    return ' '.join(np.unique(x))\n",
    "\n",
    "\n",
    "# F1 Score 함수\n",
    "def f1_score(t_true, t_pred):\n",
    "    t_true = t_true.apply(lambda x : set(x.split()))\n",
    "    t_pred = t_pred.apply(lambda x : set(x.split()))\n",
    "    \n",
    "    intersection = np.array([len(x[0] & x[1]) for x in zip(t_true, t_pred)])\n",
    "    len_t_true = t_true.apply(lambda x : len(x)).values\n",
    "    len_t_pred = t_pred.apply(lambda x : len(x)).values\n",
    "    \n",
    "    F1 = 2 * intersection / (len_t_true + len_t_pred)\n",
    "    \n",
    "    return F1\n",
    "\n",
    "# ArcFace loss 생성 Class\n",
    "class ArcMarginProduct(Layer):\n",
    "    '''\n",
    "    GDis(Geodestic Distance margin) 구하는 Class\n",
    "    Implements large margin arc distance.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, n_classes, s=30, m=0.5, easy_margin=False, ls_eps=0.0, **kwargs):\n",
    "        \n",
    "        super(ArcMarginProduct, self).__init__(**kwargs)\n",
    "        \n",
    "        self.n_classes = n_classes\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m =tf.math.cos(m)\n",
    "        self.sin_m =tf.math.sin(m)\n",
    "        self.th = tf.math.cos(math.pi - m)\n",
    "        self.mm = tf.math.sin(math.pi - m) * m\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'n_classes':self.n_classes,\n",
    "            's' : self.s,\n",
    "            'm' : self.m,\n",
    "            'ls_eps' : self.ls_eps,\n",
    "            'easy_margin' : self.easy_margin\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        super(ArcMarginProduct, self).build(input_shape[0])\n",
    "        \n",
    "        self.W = self.add_weight(\n",
    "            name='W',\n",
    "            shape=(int(input_shape[0][-1]), self.n_classes),\n",
    "            initializer = 'glorot_uniform',\n",
    "            dtype='float32',\n",
    "            trainable=True,\n",
    "            regularizer=None\n",
    "            )\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        X, y = inputs\n",
    "        y = tf.cast(y, dtype=tf.int32)\n",
    "        cosine = tf.matmul(\n",
    "            tf.math.l2_normalize(X, axis=1),\n",
    "            tf.math.l2_normalize(self.W, axis=0)\n",
    "        )\n",
    "        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        \n",
    "        if self.easy_margin:\n",
    "            phi = tf.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n",
    "            \n",
    "        one_hot = tf.cast(\n",
    "            tf.one_hot(y, depth=self.n_classes),\n",
    "            dtype=cosine.dtype\n",
    "        )\n",
    "        \n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1-self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n",
    "            \n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "        return output\n",
    "\n",
    "# KNN 이웃 구하기\n",
    "def get_neighbors(df, embeddings, KNN=50, image=True):\n",
    "    model = NearestNeighbors(n_neighbors=KNN)\n",
    "    model.fit(embeddings)\n",
    "    distances, indices = model.kneighbors(embeddings)\n",
    "    \n",
    "    if GET_CV:\n",
    "        if image :\n",
    "            thresholds = list(np.arange(3.0, 5.0, 0.1))\n",
    "        else:\n",
    "            thresholds = list(np.arange(15, 35, 1))\n",
    "            \n",
    "        scores = []\n",
    "        for threshold in thresholds:\n",
    "            predictions = []\n",
    "            for k in range(embeddings.shape[0]):\n",
    "                idx = np.where(distances[k,] < threshold)[0]\n",
    "                indc = indices[k , idx]\n",
    "                posting_ids = ' '.join(df['posting_id'].iloc[indc].values)\n",
    "                predictions.append(posting_ids)\n",
    "            df['pred_matches'] = predictions\n",
    "            df['f1'] = f1_score(df['matches'], df['pred_matches'])\n",
    "            score = df['f1'].mean()\n",
    "            \n",
    "            print('F1 score for threshold {} is {}'.format(threshold, score))\n",
    "            scores.append(score)\n",
    "            \n",
    "        thresholds_scores = pd.DataFrame({\n",
    "            'thresholds':thresholds,\n",
    "            'scores': scores\n",
    "        })\n",
    "        max_score = thresholds_scores[thresholds_scores['scores'] == thresholds_scores['scores'].max()]\n",
    "        best_threshold = max_score['thresholds'].values[0]\n",
    "        best_score = max_score['scores'].values[0]\n",
    "        \n",
    "        print('Our best score : {} , threshold : {}'.format(best_score, best_threshold))\n",
    "        print(type(best_threshold))\n",
    "        \n",
    "        del predictions, scores, indc, idx\n",
    "        \n",
    "        \n",
    "        predictions = []\n",
    "        for i in range(embeddings.shape[0]):\n",
    "            if image:\n",
    "                idx = np.where(distances[i,]<best_threshold)[0]\n",
    "            else:\n",
    "                idx = np.where(distances[i,]<best_threshold)[0]\n",
    "                \n",
    "            indc = indices[i, idx]\n",
    "            posting_ids = df['posting_id'].iloc[indc].values\n",
    "            predictions.append(posting_ids)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        predictions = []\n",
    "        for k in tqdm(range(embeddings.shape[0])):\n",
    "            if image:\n",
    "                idx = np.where(distances[k,]<3.6)[0]\n",
    "            else:\n",
    "                idx = np.where(distances[k,]<20.0)[0]\n",
    "            indc = indices[k, idx]\n",
    "            posting_ids =df['posting_id'].iloc[indc].values\n",
    "            predictions.append(posting_ids)\n",
    "            \n",
    "    del model, distances, indices, idx, indc, posting_ids\n",
    "    gc.collect()\n",
    "    \n",
    "    return df, predictions\n",
    "\n",
    "############################################################\n",
    "\n",
    "# read & decode image\n",
    "def read_and_decode_img(image):\n",
    "    image = tf.io.read_file(image)\n",
    "    img = tf.image.decode_jpeg(image, channels=3)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    return img\n",
    "\n",
    "# dataset load\n",
    "def get_dataset(image):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(image)\n",
    "    dataset = dataset.map(read_and_decode_img, \n",
    "                          num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# image embedding\n",
    "def image_embedding(img_path):\n",
    "    embeds = []\n",
    "    \n",
    "    margin = ArcMarginProduct(\n",
    "            n_classes = N_CLASSES, \n",
    "            s = 30, \n",
    "            m = 0.5, \n",
    "            name='head/arc_margin', \n",
    "            dtype='float32'\n",
    "            )\n",
    "    \n",
    "    input_layer = Input(shape = (*IMG_SIZE, 3))\n",
    "    label = Input(shape= ())\n",
    "    \n",
    "    x = efn.EfficientNetB3(weights = None, include_top=False)(input_layer)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = margin([x, label])\n",
    "    \n",
    "    output_layer = Softmax(dtype='float32')(x)\n",
    "    \n",
    "    model = Model(inputs=[input_layer, label], \n",
    "                  outputs=[output_layer])\n",
    "    model.load_weights('../input/shopeeefficientnetb3512/EfficientNetB3_512_42.h5')\n",
    "    model = Model(inputs = model.input[0], \n",
    "                  outputs = model.layers[-4].output)\n",
    "    chunk = 5000\n",
    "    iterator = np.arange(np.ceil(len(df) / chunk))\n",
    "    for j in iterator:\n",
    "        a = int(j * chunk)\n",
    "        b = int((j + 1) * chunk)\n",
    "        image_dataset = get_dataset(img_path[a:b])\n",
    "        image_embeddings = model.predict(image_dataset)\n",
    "        embeds.append(image_embeddings)\n",
    "    \n",
    "    del model\n",
    "    \n",
    "    image_embeddings = np.concatenate(embeds)\n",
    "    \n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    \n",
    "    return image_embeddings\n",
    "\n",
    "############################################################\n",
    "\n",
    "# title 단어 preprocessing\n",
    "def text_preprocessing(text, flg_stem, flg_lemm):\n",
    "    \n",
    "    stopwords_list = nltk.corpus.stopwords.words('english')\n",
    "    \n",
    "    # 특수기호 제거, 모든 문자 소문자, 양옆 공백 제거\n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "    \n",
    "    # text 문자에서 stopwords_list 에 있는 단어 제거하기\n",
    "    text_list = text.split()\n",
    "    \n",
    "    if stopwords_list is not None :\n",
    "        text_list = [word for word in text_list \n",
    "                    if word not in text_list]\n",
    "        \n",
    "    # -ing, -ly, ... 같은 접미어 제거 하기 (가지치기)\n",
    "    if flg_stem == True :\n",
    "        ps = nltk.stem.porter.PorterStemmer()\n",
    "        text_list = [ps.stem(word) for word in text_list]\n",
    "        \n",
    "    # 뿌리 단어로 바꾸기\n",
    "    if flg_lemm == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        text_list = [lem.lemmatize(word) for worf in text_list]\n",
    "        \n",
    "    # 문자열로 되돌려놓기\n",
    "    clean_text = \" \".join(text_list)\n",
    "    return text\n",
    "\n",
    "# BERT encoding 함수\n",
    "def bert_encode(texts, tokenizer, max_len=512):\n",
    "    all_tokens = []   # ==>\n",
    "    all_masks = []    # ==>\n",
    "    all_segments = [] # ==>\n",
    "    \n",
    "    for text in texts:\n",
    "        text = tokenizer.tokenize(text)\n",
    "        text = text[:max_len-2]\n",
    "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
    "        pad_len = max_len - len(input_sequence)\n",
    "        \n",
    "        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n",
    "        tokens += [0] * pad_len\n",
    "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
    "        segment_ids = [0] * max_len\n",
    "        \n",
    "        all_tokens.append(tokens)\n",
    "        all_masks.append(pad_masks)\n",
    "        all_segments.append(segment_ids)\n",
    "        \n",
    "    gc.collect()\n",
    "    \n",
    "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)\n",
    "\n",
    "# BERT Model 전이학습 함수\n",
    "def get_text_embeddings(df, max_len = 70):\n",
    "    embeds = []\n",
    "    module_url = \"../input/external-model/bert_en_uncased_L-24_H-1024_A-16_1\"\n",
    "    bert_layer = hub.KerasLayer(module_url, trainable = True)\n",
    "    vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "    do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "    tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
    "    \n",
    "    text = bert_encode(df['title'].values, tokenizer, max_len = max_len)\n",
    "    \n",
    "    margin = ArcMarginProduct(\n",
    "            n_classes = 11014, \n",
    "            s = 30, \n",
    "            m = 0.5, \n",
    "            name='head/arc_margin', \n",
    "            dtype='float32'\n",
    "            )\n",
    "    \n",
    "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    segment_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
    "    label = Input(shape = (), name = 'label')\n",
    "    \n",
    "    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "    clf_output = sequence_output[:, 0, :]\n",
    "    \n",
    "    x = margin([clf_output, label])\n",
    "    output = Softmax(dtype='float32')(x)\n",
    "    \n",
    "    model = Model(inputs = [input_word_ids, input_mask, segment_ids, label], \n",
    "                  outputs = [output])\n",
    "    model.load_weights('../input/bert-baseline/Bert_123.h5')\n",
    "    \n",
    "    model = Model(inputs = model.input[0:3], outputs = model.layers[-4].output)\n",
    "    \n",
    "    chunk = 5000\n",
    "    iterator = np.arange(np.ceil(len(df) / chunk))\n",
    "    for j in iterator:\n",
    "        \n",
    "        a = int(j * chunk)\n",
    "        b = int((j + 1) * chunk)\n",
    "\n",
    "        text_chunk = ((text[0][a:b], text[1][a:b], text[2][a:b]))\n",
    "        \n",
    "        text_embeddings = model.predict(text_chunk, batch_size = BATCH_SIZE)\n",
    "        embeds.append(text_embeddings)\n",
    "        \n",
    "    del model\n",
    "    \n",
    "    text_embeddings = np.concatenate(embeds)\n",
    "    \n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    \n",
    "    return text_embeddings\n",
    "\n",
    "###########################################################################\n",
    "# phash data\n",
    "\n",
    "def phash_match(phash_array, element):\n",
    "    phash_diff = phash_array - phash_array[element]\n",
    "    return phash_diff\n",
    "\n",
    "def add_match(phash, i, dataset, threshold = 5):\n",
    "    \n",
    "    diffs = phash_match(phash, i)\n",
    "    matches = [x for x in diffs[diffs <= threshold].index.drop(i).values]\n",
    "    \n",
    "    str_matches = ''\n",
    "    str_matches = str_matches + dataset.iloc[i, 0] + ' '\n",
    "    \n",
    "    for k in matches:\n",
    "        str_matches = str_matches + dataset.iloc[k, 0] + ' '\n",
    "    str_matches = str_matches[:-1]\n",
    "    \n",
    "    return str_matches\n",
    "\n",
    "def simple_match(dataset, element):\n",
    "    \"\"\"\n",
    "    A function that returns match names.\n",
    "    Takes dataset and i element.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    matches = dataset[dataset['image_phash'] == \n",
    "                      dataset['image_phash'][element]]['posting_id'].drop(element).values\n",
    "    str_matches = ''\n",
    "    str_matches = str_matches + dataset.iloc[element, 0] + ' '\n",
    "    for j in matches:\n",
    "        str_matches = str_matches + j + ' '\n",
    "    str_matches = str_matches[:-1]\n",
    "    result.append(str_matches)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-graduate",
   "metadata": {
    "papermill": {
     "duration": 0.028932,
     "end_time": "2021-04-26T17:50:27.818713",
     "exception": false,
     "start_time": "2021-04-26T17:50:27.789781",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DataSet 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "driving-battle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T17:50:27.885694Z",
     "iopub.status.busy": "2021-04-26T17:50:27.884907Z",
     "iopub.status.idle": "2021-04-26T17:50:27.946916Z",
     "shell.execute_reply": "2021-04-26T17:50:27.947318Z"
    },
    "papermill": {
     "duration": 0.099427,
     "end_time": "2021-04-26T17:50:27.947465",
     "exception": false,
     "start_time": "2021-04-26T17:50:27.848038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_2255846744</td>\n",
       "      <td>0006c8e5462ae52167402bac1c2e916e.jpg</td>\n",
       "      <td>ecc292392dc7687a</td>\n",
       "      <td>Edufuntoys - CHARACTER PHONE ada lampu dan mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_3588702337</td>\n",
       "      <td>0007585c4d0f932859339129f709bfdc.jpg</td>\n",
       "      <td>e9968f60d2699e2c</td>\n",
       "      <td>(Beli 1 Free Spatula) Masker Komedo | Blackhea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_4015706929</td>\n",
       "      <td>0008377d3662e83ef44e1881af38b879.jpg</td>\n",
       "      <td>ba81c17e3581cabe</td>\n",
       "      <td>READY Lemonilo Mie instant sehat kuah dan goreng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        posting_id                                 image       image_phash  \\\n",
       "0  test_2255846744  0006c8e5462ae52167402bac1c2e916e.jpg  ecc292392dc7687a   \n",
       "1  test_3588702337  0007585c4d0f932859339129f709bfdc.jpg  e9968f60d2699e2c   \n",
       "2  test_4015706929  0008377d3662e83ef44e1881af38b879.jpg  ba81c17e3581cabe   \n",
       "\n",
       "                                               title  \n",
       "0  Edufuntoys - CHARACTER PHONE ada lampu dan mus...  \n",
       "1  (Beli 1 Free Spatula) Masker Komedo | Blackhea...  \n",
       "2   READY Lemonilo Mie instant sehat kuah dan goreng  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, df_cu, img_paths = read_dataset()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-malaysia",
   "metadata": {
    "papermill": {
     "duration": 0.017109,
     "end_time": "2021-04-26T17:50:27.982019",
     "exception": false,
     "start_time": "2021-04-26T17:50:27.964910",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Image embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "connected-rocket",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T17:50:28.020163Z",
     "iopub.status.busy": "2021-04-26T17:50:28.019622Z",
     "iopub.status.idle": "2021-04-26T17:50:39.130157Z",
     "shell.execute_reply": "2021-04-26T17:50:39.128696Z"
    },
    "papermill": {
     "duration": 11.130918,
     "end_time": "2021-04-26T17:50:39.130291",
     "exception": false,
     "start_time": "2021-04-26T17:50:27.999373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1536)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_embeddings = image_embedding(img_paths)\n",
    "image_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-mixer",
   "metadata": {
    "papermill": {
     "duration": 0.017626,
     "end_time": "2021-04-26T17:50:39.165935",
     "exception": false,
     "start_time": "2021-04-26T17:50:39.148309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Text embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ranging-venice",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T17:50:39.205697Z",
     "iopub.status.busy": "2021-04-26T17:50:39.205202Z",
     "iopub.status.idle": "2021-04-26T17:51:24.763755Z",
     "shell.execute_reply": "2021-04-26T17:51:24.764196Z"
    },
    "papermill": {
     "duration": 45.580816,
     "end_time": "2021-04-26T17:51:24.764343",
     "exception": false,
     "start_time": "2021-04-26T17:50:39.183527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1024)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['title'] = df['title'].map(lambda x: text_preprocessing(x, True, True))\n",
    "\n",
    "text_embeddings = get_text_embeddings(df)\n",
    "text_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-posting",
   "metadata": {
    "papermill": {
     "duration": 0.018178,
     "end_time": "2021-04-26T17:51:24.800967",
     "exception": false,
     "start_time": "2021-04-26T17:51:24.782789",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## TF-IDF Text embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "motivated-prison",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T17:51:24.842963Z",
     "iopub.status.busy": "2021-04-26T17:51:24.841287Z",
     "iopub.status.idle": "2021-04-26T17:51:24.843637Z",
     "shell.execute_reply": "2021-04-26T17:51:24.844049Z"
    },
    "papermill": {
     "duration": 0.024942,
     "end_time": "2021-04-26T17:51:24.844178",
     "exception": false,
     "start_time": "2021-04-26T17:51:24.819236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = TfidfVectorizer(stop_words=None, binary=True, max_features=15500)\n",
    "# text_tfidf = model.fit_transform(df_cu.title).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "legitimate-bride",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T17:51:24.886760Z",
     "iopub.status.busy": "2021-04-26T17:51:24.886202Z",
     "iopub.status.idle": "2021-04-26T17:51:24.889532Z",
     "shell.execute_reply": "2021-04-26T17:51:24.889946Z"
    },
    "papermill": {
     "duration": 0.027732,
     "end_time": "2021-04-26T17:51:24.890072",
     "exception": false,
     "start_time": "2021-04-26T17:51:24.862340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\npreds = []\\nCHUNK = 1024*4\\n\\nprint('Find similar titles by TF-IDF model')\\nCTS = len(df_cu)//CHUNK\\nif len(df_cu)%CHUNK!=0: CTS += 1\\nfor i in range(CTS):\\n    a = i*CHUNK\\n    b = (i+1)*CHUNK\\n    b = min(b,len(df_cu))\\n    print('chunk',a,'to',b)\\n    \\n    # Cosine Similarity Distance\\n    cts = cupy.matmul(text_tfidf, text_tfidf[a:b].T).T\\n    \\n    for k in range(b-a):\\n        IDX = cupy.where(cts[k,]>0.75)[0]\\n        x = df_cu.iloc[cupy.asnumpy(IDX)].posting_id.to_pandas().values\\n        preds.append(x)\\n\\ngc.collect()\\n        \\ndf_cu['tfidf_text_pred'] = preds\\n\\ndel model, text_tfidf, preds\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "preds = []\n",
    "CHUNK = 1024*4\n",
    "\n",
    "print('Find similar titles by TF-IDF model')\n",
    "CTS = len(df_cu)//CHUNK\n",
    "if len(df_cu)%CHUNK!=0: CTS += 1\n",
    "for i in range(CTS):\n",
    "    a = i*CHUNK\n",
    "    b = (i+1)*CHUNK\n",
    "    b = min(b,len(df_cu))\n",
    "    print('chunk',a,'to',b)\n",
    "    \n",
    "    # Cosine Similarity Distance\n",
    "    cts = cupy.matmul(text_tfidf, text_tfidf[a:b].T).T\n",
    "    \n",
    "    for k in range(b-a):\n",
    "        IDX = cupy.where(cts[k,]>0.75)[0]\n",
    "        x = df_cu.iloc[cupy.asnumpy(IDX)].posting_id.to_pandas().values\n",
    "        preds.append(x)\n",
    "\n",
    "gc.collect()\n",
    "        \n",
    "df_cu['tfidf_text_pred'] = preds\n",
    "\n",
    "del model, text_tfidf, preds\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-reason",
   "metadata": {
    "papermill": {
     "duration": 0.018872,
     "end_time": "2021-04-26T17:51:24.927879",
     "exception": false,
     "start_time": "2021-04-26T17:51:24.909007",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## image embedding 값으로 prediction data 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "psychological-election",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T17:51:24.972493Z",
     "iopub.status.busy": "2021-04-26T17:51:24.971733Z",
     "iopub.status.idle": "2021-04-26T17:51:26.882748Z",
     "shell.execute_reply": "2021-04-26T17:51:26.882263Z"
    },
    "papermill": {
     "duration": 1.934584,
     "end_time": "2021-04-26T17:51:26.882881",
     "exception": false,
     "start_time": "2021-04-26T17:51:24.948297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 4002.20it/s]\n"
     ]
    }
   ],
   "source": [
    "if len(df) > 3: KNN=100\n",
    "else: KNN=3\n",
    "    \n",
    "df, image_predictions = get_neighbors(df, image_embeddings, KNN=KNN, image=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-wholesale",
   "metadata": {
    "papermill": {
     "duration": 0.019514,
     "end_time": "2021-04-26T17:51:26.922219",
     "exception": false,
     "start_time": "2021-04-26T17:51:26.902705",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## text embeddings 값으로 prediction data 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "determined-mitchell",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T17:51:26.967066Z",
     "iopub.status.busy": "2021-04-26T17:51:26.966492Z",
     "iopub.status.idle": "2021-04-26T17:51:27.502788Z",
     "shell.execute_reply": "2021-04-26T17:51:27.501544Z"
    },
    "papermill": {
     "duration": 0.560928,
     "end_time": "2021-04-26T17:51:27.502923",
     "exception": false,
     "start_time": "2021-04-26T17:51:26.941995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 2903.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if len(df) > 3: KNN=100\n",
    "else: KNN=3\n",
    "\n",
    "df, text_predictions = get_neighbors(df, text_embeddings, KNN=KNN, image=False)\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-history",
   "metadata": {
    "papermill": {
     "duration": 0.020595,
     "end_time": "2021-04-26T17:51:27.544211",
     "exception": false,
     "start_time": "2021-04-26T17:51:27.523616",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 해시값으로 동일상품 분류하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "capital-phone",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T17:51:27.605494Z",
     "iopub.status.busy": "2021-04-26T17:51:27.604859Z",
     "iopub.status.idle": "2021-04-26T17:51:27.607670Z",
     "shell.execute_reply": "2021-04-26T17:51:27.608173Z"
    },
    "papermill": {
     "duration": 0.043402,
     "end_time": "2021-04-26T17:51:27.608311",
     "exception": false,
     "start_time": "2021-04-26T17:51:27.564909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>phash_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_2255846744</td>\n",
       "      <td>0006c8e5462ae52167402bac1c2e916e.jpg</td>\n",
       "      <td>ecc292392dc7687a</td>\n",
       "      <td>Edufuntoys - CHARACTER PHONE ada lampu dan mus...</td>\n",
       "      <td>[test_2255846744]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_3588702337</td>\n",
       "      <td>0007585c4d0f932859339129f709bfdc.jpg</td>\n",
       "      <td>e9968f60d2699e2c</td>\n",
       "      <td>(Beli 1 Free Spatula) Masker Komedo | Blackhea...</td>\n",
       "      <td>[test_3588702337]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_4015706929</td>\n",
       "      <td>0008377d3662e83ef44e1881af38b879.jpg</td>\n",
       "      <td>ba81c17e3581cabe</td>\n",
       "      <td>READY Lemonilo Mie instant sehat kuah dan goreng</td>\n",
       "      <td>[test_4015706929]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        posting_id                                 image       image_phash  \\\n",
       "0  test_2255846744  0006c8e5462ae52167402bac1c2e916e.jpg  ecc292392dc7687a   \n",
       "1  test_3588702337  0007585c4d0f932859339129f709bfdc.jpg  e9968f60d2699e2c   \n",
       "2  test_4015706929  0008377d3662e83ef44e1881af38b879.jpg  ba81c17e3581cabe   \n",
       "\n",
       "                                               title         phash_pred  \n",
       "0  Edufuntoys - CHARACTER PHONE ada lampu dan mus...  [test_2255846744]  \n",
       "1  (Beli 1 Free Spatula) Masker Komedo | Blackhea...  [test_3588702337]  \n",
       "2   READY Lemonilo Mie instant sehat kuah dan goreng  [test_4015706929]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# 해시값으로 동일상품 분류\n",
    "#phashs = df['image_phash'].apply(lambda x: imagehash.hex_to_hash(x))\n",
    "\n",
    "phash_df = df[['posting_id', 'image_phash']]\n",
    "str_matches = []\n",
    "for i in tqdm(range(len(phash_df)), \n",
    "                   desc = 'Progress:', \n",
    "                   position = 0, \n",
    "                   leave = True):\n",
    "    str_matches.append(simple_match(phash_df, i))\n",
    "\n",
    "df['phash_pred'] = str_matches\n",
    "df.head()\n",
    "'''\n",
    "tmp = df.groupby('image_phash').posting_id.unique().to_dict()\n",
    "df['phash_pred'] = df.image_phash.map(tmp)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-friendly",
   "metadata": {
    "papermill": {
     "duration": 0.020814,
     "end_time": "2021-04-26T17:51:27.650353",
     "exception": false,
     "start_time": "2021-04-26T17:51:27.629539",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 예측값 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "capital-isaac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-26T17:51:27.700429Z",
     "iopub.status.busy": "2021-04-26T17:51:27.699806Z",
     "iopub.status.idle": "2021-04-26T17:51:27.794513Z",
     "shell.execute_reply": "2021-04-26T17:51:27.794068Z"
    },
    "papermill": {
     "duration": 0.123216,
     "end_time": "2021-04-26T17:51:27.794636",
     "exception": false,
     "start_time": "2021-04-26T17:51:27.671420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if GET_CV:\n",
    "    df['image_pred'] = image_predictions\n",
    "    df['text_pred'] = text_predictions\n",
    "    #df['tfidf_text_pred'] = df_cu['tfidf_text_pred'].to_pandas().values\n",
    "    df['pred_matches'] = df.apply(combine_preds, axis = 1)\n",
    "    df['f1'] = f1_score(df['matches'], df['pred_matches'])\n",
    "    score = df.f1.mean()\n",
    "    print('Final F1 CV Score :', score)\n",
    "    df['matches'] = df['pred_matches']\n",
    "    df[['posting_id', 'matches']].to_csv('submission.csv', index = False)\n",
    "else:\n",
    "    df['image_pred'] = image_predictions\n",
    "    df['text_pred'] = text_predictions\n",
    "    #df['tfidf_text_pred'] = df_cu['tfidf_text_pred'].to_pandas().values\n",
    "    df['matches'] = df.apply(combine_preds, axis = 1)\n",
    "    df[['posting_id', 'matches']].to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 140.071499,
   "end_time": "2021-04-26T17:51:31.101073",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-26T17:49:11.029574",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
